{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WMT22-MasaKhane SPC",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Mount Drive"
      ],
      "metadata": {
        "id": "HZbxqzuO_HFL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "sBCOPMiL9p7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Clone WMT22-MasaKhane GitHub Repo"
      ],
      "metadata": {
        "id": "-rQP8gw5W8oT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0h1GUsEtWZqS"
      },
      "outputs": [],
      "source": [
        "%cd /content/drive/MyDrive\n",
        "\n",
        "!git clone https://github.com/abumafrim/WMT22-MasaKhane.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Set-up\n",
        "\n",
        "*   Change directory to WMT22-MasaKhane\n",
        "*   Install required libraries"
      ],
      "metadata": {
        "id": "9YctIEqpXW3f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/WMT22-MasaKhane\n",
        "\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "lnJvAXKXXbpZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Download data\n",
        "\n",
        "* MAFAND-MT\n",
        "* Huggingface LASER\n",
        "* Create Sentence-pair classification dataset"
      ],
      "metadata": {
        "id": "F64mtQHXXy1g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/WMT22-MasaKhane\n",
        "\n",
        "#Clone mafand and preprocess data files\n",
        "!git clone https://github.com/masakhane-io/lafand-mt.git\n",
        "!python3 download-and-process-mafand.py\n",
        "\n",
        "#Download Hugginface LASER and preprocess data files\n",
        "!python3 download-and-process-hug-laser.py\n",
        "\n",
        "%cd sentence-pair-classification\n",
        "!python3 create-spc-data.py"
      ],
      "metadata": {
        "id": "2sl5wqKtYAMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SPC Model\n",
        "\n",
        "\n",
        "* Train SPC Model\n",
        "* Use model to predict Huggingface LASER quality\n",
        "* Select best sentences based on 3 thresholds: **0.4, 0.5, 0.7**\n",
        "\n"
      ],
      "metadata": {
        "id": "utV8sdOVaX7F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Set-up PLM and target languages\n",
        "\n",
        "%cd /content/drive/MyDrive/WMT22-MasaKhane/sentence-pair-classification\n",
        "\n",
        "import os\n",
        "\n",
        "##Provide the model to finetune\n",
        "## Any of \"albert-base-v2\", \"albert-large-v2\", \"albert-xlarge-v2\", \"albert-xxlarge-v2\", \"bert-base-uncased\", etc\n",
        "\n",
        "model = 'albert-base-v2'\n",
        "\n",
        "##Provide the target languages in the same format\n",
        "hug_langs = ['eng-hau', 'eng-ibo', 'eng-lug', 'eng-swh', 'eng-tsn', 'eng-yor', 'eng-zul', 'fra-wol']\n",
        "maf_langs = ['en_hau', 'en_ibo', 'en_lug', 'en_swa', 'en_tsn', 'en_yor', 'en_zul', 'fr_wol']"
      ],
      "metadata": {
        "id": "bzCGGiSEUoz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train SPC Model on MAFAND-MT and Huggingface LASER Datasets\n",
        "\n",
        "for hug_lang, maf_lang in zip(hug_langs, maf_langs):\n",
        "  train_path = 'data/' + hug_lang + '/spc-' + maf_lang + '_train.tsv'\n",
        "  dev_path = 'data/' + hug_lang + '/spc-' + maf_lang + '_dev.tsv'\n",
        "  test_path = 'data/' + hug_lang + '/spc-' + maf_lang + '_test.tsv'\n",
        "\n",
        "  model_path = 'models/' + hug_lang\n",
        "  if not os.path.exists(model_path):\n",
        "    print(\"Creation of the \" + hug_lang + \" model folder...\")\n",
        "    os.makedirs(model_path)\n",
        "\n",
        "  !python3 run-sp-class.py \\\n",
        "      --train \\\n",
        "      --eval=True \\\n",
        "      --model={model} \\\n",
        "      --model_path={model_path} \\\n",
        "      --train_data={train_path} \\\n",
        "      --val_data={dev_path} \\\n",
        "      --test_data={test_path} \\\n",
        "      --epochs=4"
      ],
      "metadata": {
        "id": "ljz93MnAabD1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predict quality of Hugginface LASER Sentences\n",
        "\n",
        "for hug_lang, maf_lang in zip(hug_langs, maf_langs):\n",
        "  data_to_classify = 'data/' + hug_lang + '/spc-' + maf_lang + '_to_classify.tsv'\n",
        "  model_path = 'models/' + hug_lang\n",
        "  val_loss = 100\n",
        "\n",
        "  #Select the best model\n",
        "  for x in os.listdir(model_path):\n",
        "    if x.beginswith(model) and x.endswith(\".pt\"):\n",
        "      if float(x[x.index('loss') + 5:x.index('loss') + 9]) < val_loss:\n",
        "        val_loss = float(x[x.index('loss') + 5:x.index('loss') + 9])\n",
        "        model_name = model_path + '/' + x\n",
        "\n",
        "  output_path = 'data/' + hug_lang\n",
        "\n",
        "  #Predict sentence quality\n",
        "  !python3 predict.py \\\n",
        "      --predict \\\n",
        "      --model={model} \\\n",
        "      --model_path={model_name} \\\n",
        "      --data_path={data_to_classify} \\\n",
        "      --output_path={output_path}"
      ],
      "metadata": {
        "id": "qKHbIzS-I74G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "thresholds = [0.4, 0.5, 0.7]\n",
        "\n",
        "for hug_lang, maf_lang in zip(hug_langs, maf_langs):\n",
        "  with open('data/' + hug_lang + '/predictions.txt', 'r') as f:\n",
        "      preds = f.readlines()\n",
        "  df_pred = pd.read_csv('data/' + hug_lang + '/spc-' + maf_lang + '_to_classify.tsv', sep='\\t')\n",
        "\n",
        "  for threshold in thresholds:\n",
        "    src_correct = []\n",
        "    tgt_correct = []\n",
        "\n",
        "    for sent1, sent2, pred in zip(df_pred['sentence1'], df_pred['sentence2'], preds):\n",
        "      if float(pred) >= threshold:\n",
        "        src_correct.append(sent1)\n",
        "        tgt_correct.append(sent2)\n",
        "\n",
        "    df = pd.DataFrame(list(zip(src_correct, tgt_correct)), columns=['input', 'target'])\n",
        "    df.to_csv(os.path.join('data/' + hug_lang + '/', 'correct-translations_t_' + str(threshold) + '.tsv'), sep='\\t', index=False)\n",
        "\n",
        "    print(hug_lang, threshold, len(df))\n",
        "    print()"
      ],
      "metadata": {
        "id": "bazd6Rozd0kE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}